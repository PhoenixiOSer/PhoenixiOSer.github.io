<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>编译 on TechChao</title>
    <link>https://techchao.com/categories/%E7%BC%96%E8%AF%91/</link>
    <description>Recent content in 编译 on TechChao</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Mon, 02 Nov 2020 16:03:45 +0800</lastBuildDate><atom:link href="https://techchao.com/categories/%E7%BC%96%E8%AF%91/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>读《程序员的自我修养-链接、装载与库》—— 编译和链接</title>
      <link>https://techchao.com/blog/link_load_2/</link>
      <pubDate>Mon, 02 Nov 2020 16:03:45 +0800</pubDate>
      
      <guid>https://techchao.com/blog/link_load_2/</guid>
      <description>编译和链接 被隐藏了的过程 在开发过程中我们主要的开发环境都是流行的继承开发环境（IDE），如 Visual Studio、Xcode、等。IDE将编译和链接的过程一步完成（通常称之为构建 | Build）。这一过程都被隐藏在了代码程序的下层。
我们以C 语言入门级程序 hello.c为例：
#include &amp;quot;stdio.h&amp;quot; int main() { printf(&amp;quot;Hello World\n&amp;quot;); return 0; } 我们可以使用 gcc 最简单的命令进行编译
$gcc hello.c $./a.out Hello World 事实上，上述过程分为4个步骤分别是预处理（Prepressing）、编译（Compilation）、汇编（Assembly）和链接（Linking）。
预处理阶段 第一步预编译的过程相当于如下命令（-E表示只进行预编译）：
gcc -E hello.c -o hello.i 预编译工作是处理以**&amp;quot;#&amp;quot;**开头的预编译指令，如#include、#import、#define等，主要规则如下：
 将所有#define删除，展开替换所有的宏定义。 处理所有条件预编译指令，如#if、#ifdef、#elif、#else、#endif。 处理#include预编译指令，将被包含的文件插入到该预编译指令的位置。（递归进行，如果文件还包含其他文件也会被一起插入） 删除所有的注释，如 //,/** */等 添加行号、和文件名标识,如# 10 &amp;quot;hello.c&amp;quot; 2，以便于编译时编译器产生调试用的行号信息及用于编译时产生编译错误或警告时能够显示行号。 保留所有的 #pragma 编译器指令，因为编译器会使用它们  编译阶段 编译的过程是一系列的 词法分析、语法分析、语义分析及优化后生产相应的汇编代码文件，这块是整个程序构建的核心，也是最复杂的部分，但不是本书的重点，所以只会介绍一些基本内容。下面是编译代码的命令：
gcc -S hello.i -o hello.s 或者直接通过
gcc -S hello.c -o hello.s 都可以得到汇编输出的文件hello.s,对于C语言来说，预编译和编译的程序是cc1，对于C++是c11plus，Objective-C 是 cc1obj等。
汇编阶段 汇编器是将汇编代码转换为机器可以执行的指令，每条汇编语句几乎都对应一条机器指令。所以汇编器的过程相对于编译器的过程相对来说比较简单。</description>
    </item>
    
    <item>
      <title>读《程序员的自我修养-链接、装载与库》—— 基础知识</title>
      <link>https://techchao.com/blog/link_load/</link>
      <pubDate>Thu, 29 Oct 2020 18:56:18 +0800</pubDate>
      
      <guid>https://techchao.com/blog/link_load/</guid>
      <description>基础知识 计算机是个非常广泛的概念，大到占用数层楼的用于科学计算的超级计算机，小到手机上的嵌入式芯片都可以被称为计算机。撇开计算机硬件中纷繁复杂的各种设备、芯片及外围接口等，站在软件开发者的角度看，我们只须抓住硬件的几个关键部件。对于系统程序开发者来说，计算机多如牛毛的硬件设备中，有三个部件最为关键，它们分别是中央处理器CPU、内存和I/O控制芯片，这三个部件几乎就是计算机的核心了。
通过了解计算机核心的三个部件，我们可以大致的了解计算机运行原理，
中央处理器CPU 早期的计算机没有很复杂的图形功能，CPU的核心频率也不高，人们首先针对 CPU 的频率进行升级，从 几十 KHz 升级到现在的 4GHz，达到了目前工艺的物理极限。之后开始从数量上提升，增加 CPU 的数量。其中最常见的就是对称多处理器 SMP（Symmetrical Multi-Processing）。目前个人电脑使用多核处理器就是SMP的简化版。
系统软件传统意义上一般将用于管理计算机本身的软件成为系统软件。系统软件又可分成两块，一块是平台性的，比如操作系统内核、驱动程序、运行库和数以千计的系统工具；另外一块是用于程序开发的，比如编译器、汇编器、链接器等开发工具和开发库。
早期 CPU 资源十分为了进一步利用 CPU 资源，所以引入了操作系统，由操作系统接管所有的硬件资源，应用程序则以进程的方式运行，每个进程都有自己独立的地址空间，进程之间地址空间相互隔离，CPU 由操作系统统一进行分配，每个进程根据进程优先级的高低都有机会得到CPU，但是，如果运行时间超出了一定的时间，操作系统会暂停该进程，将CPU资源分配给其他等待运行的进程。这种CPU的分配方式即所谓的抢占式（Preemptive），如果操作系统分配给每个进程的时间都很短，即CPU在多个进程间快速地切换，从而造成了很多进程都在同时运行的假象。目前几乎所有现代的操作系统都是采用这种方式，比如我们熟悉的UNIX、Linux、Windows NT，以及Mac OS X等流行的操作系统。
I/O控制 操作系统位于硬件的上层，是对硬件的管理和抽象。作为应用开发程序员我们不用去关心底层的硬件到底是如何工作的，我们只需要调用操作系统统一的API来完成我们的开发任务。在UNIX中，硬件设备的访问形式跟访问普通的文件形式一样；在Windows系统中，图形硬件被抽象成了GDI，声音和多媒体设备被抽象成了DirectX对象；磁盘被抽象成了普通文件系统。操作系统开发者提供一系列的接口和框架，具体硬件的驱动程序则交由硬件产商实现。
磁盘驱动程序收到这个读取文件请求以后就向硬盘发出硬件命令。向硬件发送I/O命令的方式有很多种，其中最为常见的一种就是通过读写I/O端口寄存器来实现。
内存 在早期的计算机中，程序是直接运行在物理内存上的，但随着计算机的发展，为了更好的利用硬件资源。我们必须同时运行程序，那么如何分配有限的物理内存给多个程序使用。
为了更好的利用内存资源，我们增加了中间层，即使用一种间接的地址访问方法。整个想法是这样的，我们把程序给出的地址看作是一种虚拟地址（Virtual Address），然后通过某些映射的方法，将这个虚拟地址转换成实际的物理地址。每个进程都有自己独立的虚拟空间，而且每个进程只能访问自己的地址空间，这样就有效地做到了进程的隔离。
目前虚拟内存通过分页（Paging）来进行物理内存和虚拟内存的映射，分页的基本方法是把地址空间人为地等分成固定大小的页，每一页的大小由硬件决定，或硬件支持多种大小的页，由操作系统选择决定页的大小。
多线程 对于多线程，我们需要了解下线程的概念、线程的调度、线程安全、用户线程与内核线程之间的映射关系。
线程（Thread），有时被称为轻量级进程（Lightweight Process, LWP），是程序执行流的最小单元。一个标准的线程由线程ID、当前指令指针（PC）、寄存器集合和堆栈组成。通常意义上，一个进程由一个到多个线程组成，各个线程之间共享程序的内存空间（包括代码段、数据段、堆等）及一些进程级的资源（如打开文件和信号）。
线程状态包括：运行、就绪、等待。
在单处理器对应多线程的情况下，并发是一种模拟出来的状态。在每个线程切换执行我们称之为线程调度。处于运行中线程拥有一段可以执行的时间，这段时间称为时间片（Time Slice），当时间片用尽的时候，该进程将进入就绪状态。如果在时间片用尽之前进程就开始等待某事件，那么它将进入等待状态。每当一个线程离开运行状态时，调度系统就会选择一个其他的就绪线程继续执行。在一个处于等待状态的线程所等待的事件发生之后，该线程将进入就绪状态。 多个线程同时访问一个共享数据，就有可能造成“脏数据”,下面的代码执行结果可能是0、1、2。
// 线程1 i = 1; i++; // 线程2 --i; 为了保证数据的安全。我们需要将各个线程对同一个数据的访问同步（Synchronization）。所谓同步，既是指在一个线程访问数据未结束的时候，其他线程不得对同一个数据进行访问。
锁 同步最常用的方法就是加锁（LOCK），锁是一种非强制机制，每一个线程在访问数据或资源之前首先试图获取（Acquire）锁，并在访问结束之后释放（Release）锁。在锁已经被占用的时候试图获取锁时，线程会等待，直到锁重新可用。
信号量 二元信号量（Binary Semaphore）是最简单的一种锁，它只有两种状态：占用与非占用。它适合只能被唯一一个线程独占访问的资源。当二元信号量处于非占用状态时，第一个试图获取该二元信号量的线程会获得该锁，并将二元信号量置为占用状态，此后其他的所有试图获取该二元信号量的线程将会等待，直到该锁被释放。（iOS中的 dispatch_semaphore_t）
互斥锁 互斥量（Mutex）和二元信号量很类似，资源仅同时允许一个线程访问，但和信号量不同的是，信号量在整个系统可以被任意线程获取并释放，也就是说，同一个信号量可以被系统中的一个线程获取之后由另一个线程释放。而互斥量则要求哪个线程获取了互斥量，哪个线程就要负责释放这个锁，其他线程越俎代庖去释放互斥量是无效的。（ pthread_mutex ）
读写锁 读写锁（Read-Write Lock）致力于一种更加特定的场合的同步。主要针对一些多度单写的情况。读取数据并不会造成数据的不安全。线程可以同时读取数据。只要发生写时才需要锁。对于同一个锁，读写锁有两种获取方式，共享的（Shared）或独占的（Exclusive）。当锁处于自由的状态时，试图以任何一种方式获取锁都能成功，并将锁置于对应的状态。如果锁处于共享状态，其他线程以共享的方式获取锁仍然会成功，此时这个锁分配给了多个线程。然而，如果其他线程试图以独占的方式获取已经处于共享状态的锁，那么它将必须等待锁被所有的线程释放。相应地，处于独占状态的锁将阻止任何其他线程获取该锁，不论它们试图以哪种方式获取。（pthread_rwlock、iOS 可以通过dispatch_barrier_async 实现类似功能）
条件锁 条件变量（Condition Variable）作为一种同步手段，作用类似于一个栅栏。对于条件变量，线程可以有两种操作，首先线程可以等待条件变量，一个条件变量可以被多个线程等待。其次，线程可以唤醒条件变量，此时某个或所有等待此条件变量的线程都会被唤醒并继续支持。（iOS 中的NSConditionLock）</description>
    </item>
    
  </channel>
</rss>
